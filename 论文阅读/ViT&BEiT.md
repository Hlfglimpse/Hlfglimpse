# Transformer & ViT & BERT & BEiT 原理解析
---
## Transformer ： Attention is all you need
![Transformer](https://raw.githubusercontent.com/Hlfglimpse/PicGo/master/20230529162515.png)

### 自注意力机制 self attention
---
## ViT : Vision Transformer